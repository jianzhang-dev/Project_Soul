

# --- å¯¼å…¥å¿…è¦çš„åº“ ---
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import time


# --- æ¨¡å—1: PulseTGAU ---
#  è¾“å…¥x -> æ›´æ–°ç”µä½ -> å¯¹æ¯”é˜ˆå€¼ -> è„‰å†²è¾“å‡º)
class PulseTGAU(nn.Module):
    def __init__(self, feature_dim: int):
        super().__init__()
        self.threshold = nn.Parameter(torch.randn(feature_dim))
        self.intrinsic_value = nn.Parameter(torch.randn(feature_dim))
        self.feature_dim = feature_dim
        self.activation = nn.SiLU()
        self.leakage_factor = 0.95
    
    def forward(self, x: torch.Tensor, potential: torch.Tensor = None):
        # å¦‚æœæ²¡æœ‰æä¾›åˆå§‹çŠ¶æ€ï¼Œåˆ›å»ºæ–°çš„é›¶çŠ¶æ€
        if potential is None:
            batch_size = x.size(0)
            device = x.device
            potential = torch.zeros(batch_size, self.feature_dim, device=device)
        
        # ç”µä½æ›´æ–°
        potential = potential * self.leakage_factor
        potential = potential + x + self.intrinsic_value
        
        # è„‰å†²ç”Ÿæˆ
        gated_potential = potential - self.threshold
        spike_mask = (gated_potential > 0).float()
        output = self.activation(gated_potential) * spike_mask
        
        # ç”µä½é‡ç½®
        reset_amount = gated_potential * spike_mask
        potential = potential - reset_amount.detach()
        
        return output, potential



# ==============================================================================
# =================== æœ€ç»ˆã€å®Œæ•´çš„ EmergentRNN ç±»å®šä¹‰ ==========================
# ==============================================================================

# (PulseTGAU ç±»çš„å®šä¹‰ä¿æŒä¸å˜)

class EmergentVision(nn.Module):
    def __init__(self, num_rps=5, rp_size=64, img_size=28, 
                 connection_threshold=0.01, 
                 iteration_steps=12): # ã€æ–°ã€‘å†…éƒ¨æ€è€ƒçš„æ­¥æ•°
        super().__init__()
        self.num_rps = num_rps
        self.rp_size = rp_size
        self.network_size = num_rps * rp_size
        self.connection_threshold = connection_threshold
        self.iteration_steps = iteration_steps # å­˜å‚¨è¿­ä»£æ­¥æ•°

        # 1. ã€æ–°ã€‘è§†è§‰ç¼–ç å™¨ (The Eye)
        #    ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ï¼Œå°†æ‰å¹³åŒ–çš„å›¾åƒ (28*28=784) æ˜ å°„åˆ°ç½‘ç»œçš„åˆå§‹çŠ¶æ€ã€‚
        self.vision_frontend = nn.Sequential(
            # Block 1
            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32), # <-- æ–°å¢æ‰¹é‡å½’ä¸€åŒ–
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2), # 28x28 -> 14x14

            # Block 2
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64), # <-- æ–°å¢æ‰¹é‡å½’ä¸€åŒ–
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2), # 14x14 -> 7x7

            # Flatten and project
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, self.network_size) # è¾“å…¥ç»´åº¦ä¹Ÿéœ€è¦æ›´æ–°
        )
        # 2. å¾ªç¯æƒé‡ (Recurrent Weights) 
        self.recurrent_weights = nn.Parameter(
             torch.randn(self.network_size, self.network_size) * (1.0 / np.sqrt(self.network_size))
        )

        # 3. è„‰å†²ç¥ç»å…ƒå±‚ (The Neuron Core) - ä¿æŒä¸å˜ï¼
        self.neuron_core = PulseTGAU(feature_dim=self.network_size)

        # 4. å±‚å½’ä¸€åŒ– (LayerNorm) - ä¿æŒä¸å˜ï¼
        self.layer_norm = nn.LayerNorm(self.network_size)
        
        # 5. åˆ†ç±»å™¨ (Classifier) - ä¿æŒä¸å˜ï¼
        self.classifier = nn.Linear(self.network_size, 10)

    def forward(self, x: torch.Tensor):
        """
        å¤„ç†ä¸€ä¸ªMNISTå›¾åƒæ‰¹æ¬¡ã€‚
        x çš„å½¢çŠ¶: [batch_size, 1, 28, 28]
        """
        batch_size = x.shape[0]
        
        # a. ã€æ–°ã€‘ä¸€æ¬¡æ€§ç¼–ç æ•´ä¸ªå›¾åƒ
        #    é¦–å…ˆå°†å›¾åƒä» [B, 1, 28, 28] æ‰å¹³åŒ–ä¸º [B, 784]
        initial_current = self.vision_frontend(x)

        # b. ã€æ–°ã€‘å†…éƒ¨è¿­ä»£å¾ªç¯ (The "Thinking" Process)
        #    åˆå§‹åŒ–çŠ¶æ€
        potential = None
        current_spikes = torch.zeros(batch_size, self.network_size, device=x.device)
        
        #    å¼€å§‹å›ºå®šæ­¥æ•°çš„â€œæ€è€ƒâ€
        for step in range(self.iteration_steps):
            # i. è®¡ç®—æ¥è‡ªç½‘ç»œä¸Šä¸€æ­¥çŠ¶æ€çš„â€œå›å“â€
            mask = (self.recurrent_weights.abs() > self.connection_threshold).float()
            effective_recurrent_weights = self.recurrent_weights * mask
            weighted_recurrent_signal = F.linear(current_spikes, effective_recurrent_weights)

            # ii. æ€»ç”µæµ = åˆå§‹æƒ³æ³•(åªåœ¨ç¬¬ä¸€æ­¥æœ‰å½±å“) + å†…éƒ¨å›å“
            #     æˆ‘ä»¬åªåœ¨ç¬¬ä¸€æ­¥æ³¨å…¥å¤–éƒ¨ä¿¡æ¯ï¼Œä¹‹åè®©ç½‘ç»œè‡ªå·±â€œæ€è€ƒâ€ã€‚
            #     è¿™æ˜¯ä¸€ç§å¸¸è§çš„åšæ³•ï¼Œä¹Ÿå¯ä»¥è®¾è®¡æˆæ¯ä¸€æ­¥éƒ½æ³¨å…¥ã€‚
            if step == 0:
                total_current = initial_current + weighted_recurrent_signal
            else:
                total_current = weighted_recurrent_signal
            
            # iii. ç¨³å®šå¹¶æ¿€æ´»
            total_current = self.layer_norm(total_current)
            current_spikes, potential = self.neuron_core(total_current, potential)

        # c. æœ€ç»ˆå†³ç­–
        #    åœ¨ç»è¿‡å¤šè½®â€œæ€è€ƒâ€åï¼Œç”¨æœ€ç»ˆçš„ç½‘ç»œçŠ¶æ€è¿›è¡Œåˆ†ç±»ã€‚
        final_representation = current_spikes
        logits = self.classifier(final_representation)
        
        return logits
    
    # (åœ¨ EmergentRNN ç±»çš„å®šä¹‰å†…éƒ¨ï¼Œæ›¿æ¢æ‰æ—§çš„ print_connection_stats å‡½æ•°)

    def print_connection_stats(self):
        """
        ã€å¢å¼ºç‰ˆã€‘ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºæ‰“å°å½“å‰ç½‘ç»œè¿æ¥çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œ
        å¹¶ç›‘æ§è‡ªå‘è¶‹è¿‘äº0çš„è¿æ¥æ•°é‡ã€‚
        """
        with torch.no_grad():
            # --- æ—§åŠŸèƒ½ï¼šåŸºäºæ‰‹åŠ¨é˜ˆå€¼çš„ç»Ÿè®¡ (æˆ‘ä»¬ä»ç„¶ä¿ç•™å®ƒç”¨äºå¯¹æ¯”) ---
            weights_abs = self.recurrent_weights.abs()
            mask = (weights_abs > self.connection_threshold).float()
            
            total_connections = weights_abs.numel()
            active_connections = mask.sum().item()
            sparsity_manual = 100 * (1 - active_connections / total_connections)
            
            rp_size = self.rp_size
            num_rps = self.num_rps
            intra_rp_connections = 0
            inter_rp_connections = 0
            
            for i in range(num_rps):
                for j in range(num_rps):
                    sub_matrix = mask[i*rp_size:(i+1)*rp_size, j*rp_size:(j+1)*rp_size]
                    if i == j:
                        intra_rp_connections += sub_matrix.sum().item()
                    else:
                        inter_rp_connections += sub_matrix.sum().item()

            print(f"    - [æ‰‹åŠ¨å‰ªæç»Ÿè®¡ @ é˜ˆå€¼={self.connection_threshold}]")
            print(f"    - æ´»è·ƒè¿æ¥: {int(active_connections)} / {total_connections} (ç¨€ç–åº¦: {sparsity_manual:.2f}%)")
            print(f"    - RPå†…éƒ¨: {int(intra_rp_connections)} | RPä¹‹é—´: {int(inter_rp_connections)}")

            # --- ã€æ–°åŠŸèƒ½ã€‘: ç›‘æ§è‡ªå‘æ¼”åŒ–ä¸­è¶‹è¿‘äº0çš„è¿æ¥ ---
            print(f"    - [è‡ªå‘ç¨€ç–æ€§ç»Ÿè®¡ (æƒé‡ç»å¯¹å€¼)]")
            
            thresholds_to_check = [0.01, 0.001, 0.0001]
            for thr in thresholds_to_check:
                # è®¡ç®—æƒé‡ç»å¯¹å€¼å°äºå½“å‰æ£€æŸ¥é˜ˆå€¼çš„è¿æ¥æ•°é‡
                near_zero_count = (weights_abs < thr).sum().item()
                percentage = 100 * near_zero_count / total_connections
                print(f"    - æƒé‡ < {thr}: {near_zero_count} ä¸ª ({percentage:.2f}%)")



def probe_memory_vortex(model, device, probe_duration=10000):
   
    print("\n" + "="*80)
    print("ğŸŒ€âš¡ğŸŒŒ å¼€å§‹è¿›è¡Œâ€œè„‰å†²æ³¨å…¥â€å®éªŒï¼šæ¢æµ‹10000æ­¥å†…çš„æ´»è·ƒå€¼æ³¢åŠ¨...")
    print("="*80)

    model.eval()
    batch_size = 1
    
    with torch.no_grad():
        # 1. åˆå§‹åŒ–
        potential = None
        current_spikes = torch.zeros(batch_size, model.network_size, device=device)
        activity_log = []

        # 2. æ³¨å…¥ä¸€æ¬¡è„‰å†²
        impulse_image = torch.randn(batch_size, 1, 28, 28, device=device)
        initial_current = model.vision_frontend(impulse_image)

        # 3. æ¨¡æ‹Ÿ 10,000 æ­¥
        print(f"â³ å¼€å§‹æ¨¡æ‹Ÿ 10,000 æ­¥... (è¯·è€å¿ƒç­‰å¾…)")
        for t in range(probe_duration):
            if t % 1000 == 0 and t > 0:
                print(f"  ğŸš¶ å·²å®Œæˆ {t} æ­¥...")

            # a. å¾ªç¯ä¿¡å·
            mask = (model.recurrent_weights.abs() > model.connection_threshold).float()
            effective_recurrent_weights = model.recurrent_weights * mask
            weighted_recurrent_signal = F.linear(current_spikes, effective_recurrent_weights)

            # b. æ€»ç”µæµï¼ˆä»… t=0 æ³¨å…¥ï¼‰
            total_current = initial_current + weighted_recurrent_signal if t == 0 else weighted_recurrent_signal
            
            # c. ç¨³å®šå¹¶æ¿€æ´»
            if hasattr(model, 'layer_norm'):
                total_current = model.layer_norm(total_current)
            
            current_spikes, potential = model.neuron_core(total_current, potential)

            # d. è®°å½•æ´»è·ƒå€¼
            total_activity = torch.sum(current_spikes.abs()).item()
            activity_log.append(total_activity)

    # --- åˆ†æç»“æœ ---
    print(f"âœ… å®éªŒå®Œæˆï¼å…±æ¨¡æ‹Ÿ {probe_duration} ä¸ªæ—¶é—´æ­¥ã€‚")
    print(f"ğŸ“ˆ æ´»è·ƒå€¼æ—¥å¿— (å‰5æ­¥): {[f'{v:.2f}' for v in activity_log[:5]]}")
    print(f"ğŸ“ˆ æ´»è·ƒå€¼æ—¥å¿— (æœ€å5æ­¥): {[f'{v:.2f}' for v in activity_log[-5:]]}")

    peak_activity = max(activity_log[:2])
    late_activity_mean = np.mean(activity_log[5000:])  # å5000æ­¥å¹³å‡
    late_activity_std = np.std(activity_log[5000:])
    final_activity = activity_log[-1]
    decay_ratio = final_activity / peak_activity if peak_activity > 0 else 0

    min_late = min(activity_log[5000:])
    max_late = max(activity_log[5000:])

    print(f"\nğŸ“Š ç»ˆæè®°å¿†åˆ†æ (t=5000~9999):")
    print(f"  - å³°å€¼æ´»è·ƒå€¼ (t=0~1): {peak_activity:.2f}")
    print(f"  - æœ€ç»ˆæ´»è·ƒå€¼ (t=9999): {final_activity:.2f}")
    print(f"  - å5000æ­¥å¹³å‡: {late_activity_mean:.2f}")
    print(f"  - å5000æ­¥æ³¢åŠ¨ (std): {late_activity_std:.2f}")
    print(f"  - èŒƒå›´: [{min_late:.2f}, {max_late:.2f}]")
    print(f"  - è¡°å‡ç‡ (final/peak): {decay_ratio*100:.1f}%")

    # åˆ¤æ–­
    if late_activity_mean > 0.1 and decay_ratio > 0.5:
        if late_activity_std > 1.0:
            print("     âœ…âœ…âœ… æ´»è·ƒå€¼æŒç»­éœ‡è¡")
        else:
            print("\n  [ç»“è®º] ğŸŸ¢ å­˜åœ¨é•¿æœŸè®°å¿†ï¼Œä½†è¶‹äºé™æ€")
            print("     âš ï¸  å¯èƒ½å·²è¿›å…¥æ•°å€¼é”å®šæ€ï¼Œå¤±å»åŠ¨æ€æ€§")
    elif late_activity_mean > 0.01:
        print("\n  [ç»“è®º] ğŸŸ¡ è®°å¿†æŒç»­è¡°å‡ï¼Œæœªå®Œå…¨æ¶ˆå¤±")
        print("     â³ å¯èƒ½åœ¨ 20,000 æ­¥å†…æ¶ˆå¤±")
    else:
        print("\n  [ç»“è®º] ğŸ’€ è¶…é•¿æœŸè®°å¿†å®Œå…¨æ¶ˆå¤±")
        print("     âŒ ç½‘ç»œæœªèƒ½ç»´æŒä¿¡æ¯å¾ªç¯")

    print("="*80)
    return activity_log
# ...

# ==============================================================================
# =================== ã€å®Œæ•´æ›´æ–°ç‰ˆã€‘çš„ main å‡½æ•° ===============================
# ==============================================================================

def main():
    # --- 1. è¶…å‚æ•°ä¸è®¾å¤‡é…ç½® ---
    EPOCHS = 100 
    BATCH_SIZE = 128
    RP_SIZE = 72
    MAX_LEARNING_RATE = 0.001 
    ITERATION_STEPS = 12 
    
    CONNECTION_THRESHOLD = 0.0 
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"--- å¯åŠ¨ã€è§†è§‰ç½‘ç»œã€‘-> æŒ‘æˆ˜ Fashion-MNIST (ä½¿ç”¨OneCycleLR) ---")
    print(f"è®¾å¤‡: {device}\n")

    # --- 2. æ•°æ®åŠ è½½ ---
    print("æ­£åœ¨åŠ è½½ Fashion-MNIST æ•°æ®é›† (å¸¦æ•°æ®å¢å¼º)...")
    
    # ã€æ–°ã€‘ä¸ºè®­ç»ƒé›†åˆ›å»ºä¸€ä¸ªå¸¦æ•°æ®å¢å¼ºçš„ transform
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(p=0.5), # 50%çš„æ¦‚ç‡æ°´å¹³ç¿»è½¬
        transforms.RandomRotation(10), # åœ¨-10åˆ°+10åº¦ä¹‹é—´éšæœºæ—‹è½¬
        transforms.ToTensor(),
        transforms.Normalize((0.2860,), (0.3530,))
    ])
    
    # ã€ä¸å˜ã€‘æµ‹è¯•é›†æ°¸è¿œä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œä»¥ä¿è¯è¯„ä¼°çš„å…¬æ­£æ€§
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.2860,), (0.3530,))
    ])
    
    # åº”ç”¨æ–°çš„ transform
    train_dataset = datasets.FashionMNIST('data', train=True, download=True, transform=train_transform)
    test_dataset = datasets.FashionMNIST('data', train=False, transform=test_transform)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
    print("æ•°æ®é›†åŠ è½½å®Œæ¯•ã€‚\n")

       # --- 3. æ¨¡å‹ã€æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨åˆå§‹åŒ– ---
    print("æ­£åœ¨åˆå§‹åŒ– EmergentVision æ¨¡å‹...")
    
    # a. å…ˆåœ¨CPUä¸Šåˆ›å»ºåŸºç¡€æ¨¡å‹
    model = EmergentVision(
        rp_size=RP_SIZE,
        connection_threshold=CONNECTION_THRESHOLD,
        iteration_steps=ITERATION_STEPS
    )
    

    model.vision_frontend = nn.Sequential(
        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
        nn.BatchNorm2d(32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Flatten(),
        nn.Linear(64 * 7 * 7, model.network_size) # ä½¿ç”¨ model.network_size ç¡®ä¿ä¸€è‡´æ€§
    )

    # c. ã€æ ¸å¿ƒä¿®æ­£ã€‘æœ€åï¼Œå°†æ•´ä¸ªã€å®Œæ•´çš„ã€æ›¿æ¢å¥½ç»„ä»¶çš„æ¨¡å‹ï¼Œä¸€æ¬¡æ€§ç§»åŠ¨åˆ°GPU
    model.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=MAX_LEARNING_RATE) 
    
    from torch.optim.lr_scheduler import OneCycleLR
    scheduler = OneCycleLR(
        optimizer, 
        max_lr=MAX_LEARNING_RATE,
        steps_per_epoch=len(train_loader),
        epochs=EPOCHS,
        pct_start=0.2
    )
    
    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹åˆå§‹åŒ–å®Œæ¯•ã€‚æ€»å¯è®­ç»ƒå‚æ•°: {num_params:,}\n")

    # --- 4. è®­ç»ƒä¸è¯„ä¼°å¾ªç¯ ---
    for epoch in range(1, EPOCHS + 1):
        start_time = time.time()
        model.train()
        total_train_loss = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # ã€æ ¸å¿ƒä¿®æ”¹ã€‘OneCycleLRéœ€è¦åœ¨æ¯ä¸ªbatchç»“æŸåéƒ½æ›´æ–°
            scheduler.step()
            
            total_train_loss += loss.item()

        avg_train_loss = total_train_loss / len(train_loader)
        
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()

        accuracy = 100 * correct / total
        epoch_time = time.time() - start_time

          # --- æ‰“å°å‘¨æœŸæŠ¥å‘Š (æˆ‘ä»¬å¯ä»¥å¢åŠ æ‰“å°å½“å‰å­¦ä¹ ç‡) ---
        current_lr = optimizer.param_groups[0]['lr']
        print(f"--- Epoch {epoch}/{EPOCHS} ---")
        print(f"è€—æ—¶: {epoch_time:.2f}s | å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")
        print(f"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%")
        if hasattr(model, 'print_connection_stats'):
            model.print_connection_stats()
        print("-" * (21 + len(str(EPOCHS)) + len(str(epoch))))

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ç»ˆæ¨¡å‹åœ¨ Fashion-MNIST æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º: {accuracy:.2f}%")
    



    # ã€æ–°å¢è¿™è¡Œã€‘åœ¨æ‰€æœ‰äº‹æƒ…éƒ½åšå®Œåï¼Œè°ƒç”¨è¯Šæ–­å‡½æ•°
    probe_memory_vortex(model, device)

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    main()